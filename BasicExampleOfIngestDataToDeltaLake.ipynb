{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "700f6bd9-0d86-4b49-8743-4bca70c05a0e",
   "metadata": {},
   "source": [
    "# このノートブックについて"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45b7283-0d6b-4be2-8aa5-7176ff01600e",
   "metadata": {},
   "source": [
    "Apahce Kafkaクラスタから読み込み、Delta Lakeに書き込む例。\n",
    "今回はシンプルに読んだまま書き込む例とする。\n",
    "\n",
    "多くのケースでは、読まれたデータを変換（フォーマット変換、数値変換、ID変換など）する必要があることに注意。\n",
    "またApache Kafkaクラスタにはストリームデータとして情報が書き込まれることを考慮し、ここではApache SparkのStructured Streamingを利用して書き込むことにする。\n",
    "\n",
    "なお、世の中にはKafka ConnectのDelta Lake Sinkもあるようなのでそちらも参考になると思われる（動作確認は未実施）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1315e2d2-87bc-40f1-827c-e1abbd6e9172",
   "metadata": {},
   "source": [
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "951458b8-734b-4746-87bb-bd87084d629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.types import StringType\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37728b92-9796-4c44-b9bf-0f96ee4e8a43",
   "metadata": {},
   "source": [
    "今回の例では、あらかじめノートブックを起動する際に環境変数で書き込み先を指定している例としている。\n",
    "必要に応じて以下を編集して書き込み先を定義すること。\n",
    "\n",
    "なお、本プロジェクトにはJupyter LabをPySparkと連係するためのヘルパーシェルスクリプトを同梱しているが、その中でApache Spark起動時のオプションとして `--conf \"spark.hadoop.fs.s3a.aws.credentials.provider=com.amazonaws.auth.DefaultAWSCredentialsProviderChain\"` を指定している。\n",
    "このため、AWS CLI等を利用して設定した `~/.aws/credentials` にあるクレデンシャル情報を利用してAWS S3にアクセスするようになっている。\n",
    "\n",
    "もしMinIO等S3互換ストレージを利用する場合は、クレデンシャルの内容を適切に設定しておく必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df590956-a1c1-4c0c-85a9-8469040648fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_location = 'file:///tmp/_checkpoints/etl-from-json'\n",
    "output_base_url = os.environ['OUTPUT_URL']\n",
    "output_url = output_base_url + 'el_aircon'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6dc54c-f18e-40e4-ab22-0f6dc96d8152",
   "metadata": {},
   "source": [
    "今回は簡単な動作確認目的であるため、1ノード上にPythonクライアントとApache Kafkaのブローカが存在する前提としている。\n",
    "別途クラスタを立ててそちらに書き込まれている場合は、必要に応じて `bootstrap_servers` の内容を編集すること。\n",
    "\n",
    "またトピックも、Apache Kafkaクラスタへのデータ書き込み時に使用したものを利用すること。もし変更していたら、編集していただきたい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1a72259-2502-49d1-90e3-83441f04f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_servers = 'localhost:9092'\n",
    "topic_name = 'el_aircon'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfe2566-d2c7-4708-8e12-905b6353e8df",
   "metadata": {},
   "source": [
    "Apache Sparkのストリーム処理定義（Apache Kafkaからの読み込み、Delta Lakeへの書き込み）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d992ccd4-ce02-46e5-b07f-32f3743e321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", bootstrap_servers) \\\n",
    "  .option(\"startingOffsets\", \"earliest\") \\\n",
    "  .option(\"subscribe\", topic_name) \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3c66d2d-f074-4b7f-9110-7e5386886d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = df.select(df['key'].cast(StringType()).alias('id'), df['value'].cast(StringType()).alias('state'), df['*'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9770334a-2d67-4449-bd16-d63225a3841f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/25 23:10:30 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7f746e64a690>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.writeStream \\\n",
    "  .format(\"delta\") \\\n",
    "  .outputMode(\"append\") \\\n",
    "  .option(\"checkpointLocation\", checkpoint_location) \\\n",
    "  .start(output_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ff144d-e73a-410c-91b5-6ef3c33f29e3",
   "metadata": {},
   "source": [
    "上記を実行後に、 [BasicExampleOfKafkaECHONETLite.ipynb] などを利用し、Apache Kafkaの `el_aircon` トピックにデータを書き込む。\n",
    "手動でやってもいいし、当該ノートブックを自動起動するようにしておいてもよい。\n",
    "\n",
    "その作業をしているのを待つためにスリープを挟む。\n",
    "\n",
    "[BasicExampleOfKafkaECHONETLite.ipynb]: https://github.com/dobachi/PythonKafkaECHONETLiteExample/blob/main/BasicExampleOfKafkaECHONETLite.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bb5cbb3-ec91-4aee-8fde-2ebad5e28fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac3d85d-0b8e-473a-8bea-05f408885689",
   "metadata": {},
   "source": [
    "# 書き込まれたデータを読み取る"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfcbdbb-5d0a-414c-af1c-64a0335eeb12",
   "metadata": {},
   "source": [
    "Delta Lakeとして書き込まれたデータを確認するため、今度はストリームではなくバッチ的に読み取って確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e0f3784-ea72-4b02-8dcc-79b9cc394185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, state: string, key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "written_df = spark.read.format('delta').load(output_url)\n",
    "written_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc92ced8-fd2d-46fa-8d3a-135c8a452a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+--------------------+----------------+---------+---------+------+--------------------+-------------+\n",
      "|          id|state|                 key|           value|    topic|partition|offset|           timestamp|timestampType|\n",
      "+------------+-----+--------------------+----------------+---------+---------+------+--------------------+-------------+\n",
      "|0068#0x0,0x1|49,21|[30 30 36 38 23 3...|[34 39 2C 32 31]|el_aircon|        0|     0|2021-10-17 00:04:...|            0|\n",
      "|0068#0x0,0x1|49,21|[30 30 36 38 23 3...|[34 39 2C 32 31]|el_aircon|        0|     1|2021-10-17 00:04:...|            0|\n",
      "|0068#0x0,0x1|49,21|[30 30 36 38 23 3...|[34 39 2C 32 31]|el_aircon|        0|     2|2021-10-17 00:04:...|            0|\n",
      "|0748#0x0,0x1|49,20|[30 37 34 38 23 3...|[34 39 2C 32 30]|el_aircon|        0|     3|2021-10-25 22:47:...|            0|\n",
      "|0748#0x0,0x1|49,20|[30 37 34 38 23 3...|[34 39 2C 32 30]|el_aircon|        0|     4|2021-10-25 22:47:...|            0|\n",
      "|0748#0x0,0x1|49,20|[30 37 34 38 23 3...|[34 39 2C 32 30]|el_aircon|        0|     5|2021-10-25 22:47:...|            0|\n",
      "|0475#0x0,0x1|49,20|[30 34 37 35 23 3...|[34 39 2C 32 30]|el_aircon|        0|     6|2021-10-25 22:48:...|            0|\n",
      "|0475#0x0,0x1|49,25|[30 34 37 35 23 3...|[34 39 2C 32 35]|el_aircon|        0|     7|2021-10-25 22:48:...|            0|\n",
      "|0475#0x0,0x1|48,25|[30 34 37 35 23 3...|[34 38 2C 32 35]|el_aircon|        0|     8|2021-10-25 22:48:...|            0|\n",
      "|0379#0x0,0x1|48,25|[30 33 37 39 23 3...|[34 38 2C 32 35]|el_aircon|        0|    10|2021-10-25 23:11:...|            0|\n",
      "|0379#0x0,0x1|48,25|[30 33 37 39 23 3...|[34 38 2C 32 35]|el_aircon|        0|    11|2021-10-25 23:11:...|            0|\n",
      "|0379#0x0,0x1|48,25|[30 33 37 39 23 3...|[34 38 2C 32 35]|el_aircon|        0|     9|2021-10-25 23:11:...|            0|\n",
      "+------------+-----+--------------------+----------------+---------+---------+------+--------------------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "written_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07199890-b711-4137-a050-b09d72b05672",
   "metadata": {},
   "source": [
    "以下のような出力が見られただろうか？\n",
    "\n",
    "```\n",
    "+------------+-----+--------------------+----------------+---------+---------+------+--------------------+-------------+\n",
    "|          id|state|                 key|           value|    topic|partition|offset|           timestamp|timestampType|\n",
    "+------------+-----+--------------------+----------------+---------+---------+------+--------------------+-------------+\n",
    "|0379#0x0,0x1|48,25|[30 33 37 39 23 3...|[34 38 2C 32 35]|el_aircon|        0|    10|2021-10-25 23:11:...|            0|\n",
    "|0379#0x0,0x1|48,25|[30 33 37 39 23 3...|[34 38 2C 32 35]|el_aircon|        0|    11|2021-10-25 23:11:...|            0|\n",
    "|0379#0x0,0x1|48,25|[30 33 37 39 23 3...|[34 38 2C 32 35]|el_aircon|        0|     9|2021-10-25 23:11:...|            0|\n",
    "+------------+-----+--------------------+----------------+---------+---------+------+--------------------+-------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac538560-39c0-49c3-81e0-7c1b74575d92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
